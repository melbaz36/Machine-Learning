import numpy as np, pandas as pd, seaborn as sns, matplotlib.pyplot as plt
from sklearn.datasets import make_blobs
from sklearn.datasets import make_moons
from sklearn.cluster import KMeans 
d=pd.read_csv("Customer data.csv")
[row1,columns1]=np.shape(d)
k=4
centroids=[]

# x=d.iloc[:,1:8]
# y=d.iloc[3,1:8]
# X = np.sum(np.square(x - y))
# Eucledian distance Pearson correlation distance
new_d=d.iloc[:,1:columns1]
[rows,columns]=np.shape(new_d)
matrix=pd.DataFrame(new_d).to_numpy()
Centroids=d.iloc[0:k,1:columns1]
mat_centroid_values=pd.DataFrame(Centroids).to_numpy()
mata_centroid=np.zeros([rows,columns])
mata_centroid[0:k,0:columns1]=mat_centroid_values
distanceEuc=np.zeros([rows,k])
Distance_Type=['Eucledian distance','Pearson correlation distance']
Centroids_random=matrix[np.random.choice(rows,k,replace=False)]
def Distance( Centroids_random, matrix, Distance_Type ):
    if(Distance_Type == 'Eucledian distance'):
        for i in range(k):    
            distanceEuc[:,i] = ((matrix-Centroids_random[i])**2).sum(axis=1)
            Cluster_Distance=distanceEuc
    else:
        Cluster_Distance=np.corrcoef(Centroids_random[0:k,:],matrix)
    return Cluster_Distance
y=Distance( Centroids_random, matrix, 'Eucledian distance' )

# distance=Distance(mata_centroid, matrix,'Eucledian distance')
#def GUC_Kmean (matrix,k, Distance_Type ):
# for i in range(100):

def GUC_Kmean (Cust_Data,k, Distance_Type ):
    Centroids_random=Cust_Data[np.random.choice(rows,k,replace=False)]
    while True:
        closest=np.zeros(rows).astype(int)
        old_closest=closest.copy()
        if(Distance_Type=='Eucledian distance'):
            distance=Distance(Centroids_random,Cust_Data,'Eucledian distance')
        else:
            distance=Distance(Centroids_random,Cust_Data,'Pearson correlation distance')
        closest=np.argmin(distance,axis=1)
        for i in range(k):
            Centroids_random[i,:]=Cust_Data[closest==i].mean(axis=0)
            Distortion_Fn=(1/rows)*np.sum(Cust_Data-np.resize(Centroids_random,(rows,columns)))**2
            plt.plot(Distortion_Fn,k)
            if(Distance_Type=='Eucledian distance'):
                Final_Cluster_distance=Distance(Centroids_random,Cust_Data,'Eucledian distance')
            else:
                Final_Cluster_distance=Distance(Centroids_random,Cust_Data,'Pearson correlation distance')
        if any(closest==old_closest):
            break
    return  Final_Cluster_distance,Distortion_Fn
# def GUC_Kmean (matrix,k, Distance_Type ):
#     while True:
#         closest=np.zeros(rows).astype(int)
#         old_closest=closest.copy()
#         if(Distance_Type=='Eucledian distance'):
#             distance=Distance(Centroids_random,matrix,'Eucledian distance')
#         else:
#             distance=Distance(Centroids_random,matrix,'Pearson correlation distance')
#         closest=np.argmin(distance,axis=1)
#         for i in range(k):
#             Centroids_random[i,:]=matrix[closest==i].mean(axis=0)
#             distortion_function=(1/rows)*np.sum(matrix-Centroids_random)**2
#             plt.plot(distortion_function,k)
#             if(Distance_Type=='Eucledian distance'):
#                 Final_Cluster_distance=Distance(Centroids_random,matrix,'Eucledian distance')
#             else:
#                 Final_Cluster_distance=Distance(Centroids_random,matrix,'Pearson correlation distance')
                
#         if (closest.all()==old_closest.all()):
#             break
   
# return  Final_Cluster_distance,distortion_function
k_means_customer_data=GUC_Kmean(matrix,k,'Eucledian distance' )
kmeans = KMeans(n_clusters=4)
kmeans.fit(matrix)
def display_cluster(X,km=[],num_clusters=0):
    color = 'brgcmyk' #List colors
    alpha = 0.5 #color obaque
    s = 20
    if num_clusters == 0:
        plt.scatter(X[:,0],X[:,1],c = color[0],alpha = alpha,s = s)
    else:
        for i in range(num_clusters):
            
            plt.scatter(X[kmeans.labels_==i,0],X[kmeans.labels_==i,1],c = color[i],alpha = alpha,s=s)
            plt.scatter(kmeans.cluster_centers_[i][0],kmeans.cluster_centers_[i][1],c = color[i]
, marker = 'x', s = 100)

o=display_cluster(matrix,km=[],num_clusters=4)
plt.rcParams['figure.figsize'] = [8,8]
sns.set_style("whitegrid")
sns.set_context("talk")
# Produce a data set that represent the x and y o coordinates of a circle
# this part can be replaced by data that you import froma file
angle = np.linspace(0,2*np.pi,20, endpoint = False)
X = np.append([np.cos(angle)],[np.sin(angle)],0).transpose()
# Data is displayed
# to display the data only it is assumed that the number of clusters is zero which is the
l=display_cluster(X)
n_samples = 1000
n_bins = 4
centers = [(-3, -3), (0, 0), (3, 3), (6, 6), (9,9)]
X, y = make_blobs(n_samples=n_samples, n_features=2, cluster_std=1.0,
centers=centers, shuffle=False, random_state=42)
n_samples = 1000
X, y = noisy_moons = make_moons(n_samples=n_samples, noise= .1)
a=display_cluster(X)
k_means_Examples= GUC_Kmean (np.resize(X,(rows,columns)),k,'Eucledian distance' )

   
# for i in range(k):
#     Centroids_random[i,:]=distance[minimum_index==i].mean(axis=0)
    
        
    # return [ Final_Cluster_Distance , Cluster_Metric ]


# diff= np.sum(np.square(Centroids-new_d))
# centroids_test=[1,2,3,4,5,6,7]
# test_difference=(new_d-centroids_test)**2
# test_sum_2=pd.DataFrame.sum(test_difference,1)

# for i in range(2000):
#     difference=centroids_test-test_sum_2.iloc[i] 
# for i in range(1,k+1):
#     rows=np.random.randint(2,2001)#return
#     columns=np.random.randint(1,8)
#     centroids=np.append(centroids,d.iloc[[rows],[columns]])
